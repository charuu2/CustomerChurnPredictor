{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332716f2-b206-4173-8d94-a2f98e44482f",
   "metadata": {},
   "source": [
    "# CUSTOMER CHURN PREDICTION MODEL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d005aa-725b-4893-a2ec-08d568f9f741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5858cf-99ad-409f-b634-dfb05cc8ca27",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b2932-52d7-4657-bbff-fedd7658e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dcd6a-99b7-4b1e-b806-93b536f613e2",
   "metadata": {},
   "source": [
    "## 2. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b46ecd-2540-4c94-88fe-82debdbed9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a2743-ddc0-46b1-bcd8-42adf0187f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc5e12-41fd-429c-af48-d3746d32aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c622b37-1cc0-4278-8db0-ae4aa0d92621",
   "metadata": {},
   "source": [
    "## 3.EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ea9aa-1bc6-42ce-945b-34f11f8e790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83a345a-4be2-41ee-8021-e0867823579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177d591-3d60-4b2e-a8d5-06d166268bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8e654-e05e-4d8d-84c9-5c9f391cebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286705b-817e-42f2-9282-d7007233218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ae0df-0dd6-4dd3-918c-0eb74e5bb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08842b15-a38a-44c4-a32e-2332fb98b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['customerID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a9092-4c98-4d31-a4af-8ef554ee7a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720fbd1-a9c9-4ce1-84f8-22f067707d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd3c13-b0c9-4418-b151-1c25a521b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion of totalcharges to numeric\n",
    "df['TotalCharges']=pd.to_numeric(df['TotalCharges'],errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc686d94-e134-4afa-948e-64313347c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2d68a1-84b0-4832-91f5-cabffaf8988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputation by taking median\n",
    "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a6abc-1991-41ce-b1de-c4f0b8c3ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3fef62-8272-4fd3-9a8a-04749940b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features=[\n",
    "\"gender\",\n",
    "\"SeniorCitizen\",\n",
    "\"Partner\",            \n",
    "\"Dependents\",              \n",
    "\"PhoneService\",       \n",
    "\"MultipleLines\",    \n",
    "\"InternetService\",    \n",
    "\"OnlineSecurity\",    \n",
    "\"OnlineBackup\",     \n",
    "\"DeviceProtection\",    \n",
    "\"TechSupport\",     \n",
    "\"StreamingTV\",      \n",
    "\"StreamingMovies\",   \n",
    "\"Contract\",     \n",
    "\"PaperlessBilling\",  \n",
    "\"PaymentMethod\"]\n",
    "\n",
    "numerical_features=[\"tenure\",\"MonthlyCharges\",\"TotalCharges\"]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe689dfd-9d3b-4258-bd22-6c14e76cf1ab",
   "metadata": {},
   "source": [
    "### Checking class distribution of  target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaab4a8-13c7-47c2-b24e-48e6aa8ce990",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df['Churn'].value_counts())\n",
    "#imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41e259b-828a-42c8-b098-c4a840fdccc2",
   "metadata": {},
   "source": [
    "### Numerical Features -Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645d095-fec0-4007-8149-40b2e63b219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bdd43a-50d1-483f-86dc-87d6c108b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893a4d2-9f23-4b9c-9dd6-eb203cb2919a",
   "metadata": {},
   "source": [
    "Feature Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f21fe-8d66-4869-9565-658b60b36b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024d569-7757-4bd4-aed4-4170ae194c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[numerical_features].hist(bins=30,figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc762673-5c14-4833-bf11-c57bfa70cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,3,figsize=(14,4))\n",
    "df[df.Churn=='No'][numerical_features].hist(bins=30,color=\"blue\",alpha=0.5,ax=ax)\n",
    "df[df.Churn=='Yes'][numerical_features].hist(bins=30,color=\"red\",alpha=0.5,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b619a-a203-4077-8b5c-845135893d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_histogram(df, column_name):\n",
    "    \n",
    "    print(f\"Plotting histogram for column: {column_name}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.histplot(df[column_name], kde=True)\n",
    "    plt.title(f\"Distribution of {column_name}\")\n",
    "\n",
    "    # Calculate mean and median\n",
    "    col_mean = df[column_name].mean()\n",
    "    col_median = df[column_name].median()\n",
    "    \n",
    "    # Add vertical lines\n",
    "    plt.axvline(col_mean, color='red', linestyle='--', label='Mean')\n",
    "    plt.axvline(col_median, color='green', linestyle='-', label='Median')\n",
    "\n",
    "   \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2321135-8308-4042-9e59-27221f718a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, \"tenure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37161b-f753-4777-8530-bbec5f6aee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, \"MonthlyCharges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea784d-6201-4a84-987c-a1838cb73fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, \"TotalCharges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe2ad9-a2d9-4671-aea9-a3afb3d0e19c",
   "metadata": {},
   "source": [
    "### Box plot for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5044fc71-483a-4863-aa0d-b818f6cc064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_boxplot(df, column_name):\n",
    "    \n",
    "    print(f\"Plotting histogram for column: {column_name}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    sns.boxplot(y=df[column_name])\n",
    "    plt.title(f\"Box plot  of {column_name}\")\n",
    "\n",
    "    plt.ylabel(column_name)\n",
    "    plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c839b24-8f68-4a9f-bafb-83e852fdc122",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df,'tenure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c31a9-240f-493d-a21b-fb1daf45d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df,'TotalCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b0dfc-187e-46c7-a18c-1594f0fea3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boxplot(df,'MonthlyCharges')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd62fe-97fc-418b-b98f-bcf594b7dad5",
   "metadata": {},
   "source": [
    "### Correlation Heatmap for numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28a0d5e-0645-4356-a7b4-2ab9de70c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.heatmap(df[['tenure','MonthlyCharges','TotalCharges']].corr(),annot=True,cmap='coolwarm',fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213c8fa-0b1b-40d3-a987-927c67939fcd",
   "metadata": {},
   "source": [
    "### Categorical Features - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d26a3d2-e4dd-4ade-9f88-195f458be8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1610268-8a2e-453c-8ec4-9dae6b8e856f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9343db0-7ba0-40c1-854e-7373cd2c8f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_features:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.countplot(x=df[col])\n",
    "    plt.title(f\"Count plot of {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea26ecb-e216-4552-bff0-0206f3e4d3ec",
   "metadata": {},
   "source": [
    "# 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb371d88-158e-4c32-89f4-49a432ebc28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ac852-8693-4dc9-8d02-0ab8a4c823d7",
   "metadata": {},
   "source": [
    "### Label Encoding for cateogrical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df7cb85-1574-4eb1-b49f-5118b5421a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = df['Contract'].unique()\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08766db5-5c58-495b-9994-8699c0f5c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col != \"Churn\":  # Exclude the target column\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964beb5e-c137-487a-b1af-a4f991d1dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label_encoders.pkl\", \"wb\") as f:\n",
    "    pickle.dump(label_encoders, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de1abf-6412-49b7-b400-9aec610ad5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fff82-5e01-41be-a323-f03989f07457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target column separately (if it's categorical)\n",
    "df_encoded[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})  # Adjust mapping as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0870cfc-22c9-4c22-92fa-900d261a5bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bb60c-a2d9-4db6-baaf-0f67b11967ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())  # Look for object-type columns that were encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea298c9e-f60a-46ea-a2d2-f573f7626a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Target variable\n",
    "df_encoded['Churn'] = df_encoded['Churn'].replace({\"Yes\": 1, \"No\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5176d039-010b-472c-8088-cd5aba8bf202",
   "metadata": {},
   "source": [
    "### Splitting the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ab0c3-784b-4c09-b165-679f1eb28aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the features and target\n",
    "X = df_encoded.drop(columns=[\"Churn\"])\n",
    "y = df_encoded[\"Churn\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a50a0-1477-480b-9933-fba5f554470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd136388-2d8a-411b-a900-c647692509a5",
   "metadata": {},
   "outputs": [],
   "source": [
    " print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208da17c-7735-44cb-ae83-8d6cf569083d",
   "metadata": {},
   "source": [
    "### Synthetic Minority OverSampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ea327-c791-4207-a478-034034c172e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we apply smote after splitting \n",
    "#smote doesnt work with missing values\n",
    "smote = SMOTE(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa9638-2aec-46c1-8053-fa5f2382a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ca110-dfb1-45fa-ae2c-f65711e61d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419a24fe-75ed-4a31-bbd0-5554ba2e3d33",
   "metadata": {},
   "source": [
    "# 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1e3f2-89db-493e-9a39-96f6499199d8",
   "metadata": {},
   "source": [
    "### Training with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb1a9d-fc64-4a24-a31a-3739e2f47b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=7, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddf971-083c-4906-8729-9d1cf6e939ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv_scores = {}\n",
    "trained_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name} with optimized parameters\")\n",
    "    \n",
    "    # Train & Store Model\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    trained_models[model_name] = model\n",
    "    \n",
    "    # Cross-validation\n",
    "    scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5, scoring=\"accuracy\")\n",
    "    cv_scores[model_name] = scores\n",
    "    print(f\"{model_name} cross-validation accuracy: {np.mean(scores):.4f}\")\n",
    "    print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee267cf-bc13-44ad-b4c6-ff6968e37644",
   "metadata": {},
   "source": [
    "## MODEL SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d58977-f18a-4395-b6dd-918162c3a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea54d5b8-d5d2-4916-b4de-0ab95694d165",
   "metadata": {},
   "source": [
    "XGBoost  gives the highest accuracy compared to other models with deafult parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9c99f-db9e-473f-951f-5ee67ac36c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42, \n",
    "    use_label_encoder=False, \n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1]),  # Balances the classes\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86999f28-376a-4c9d-b853-394b6009cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict on test data\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3edc7-39e0-40aa-9d00-020de1e8094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb4ab6-b4d4-4ef2-a534-ec6b091228ac",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8125362-d578-4f45-9a4f-f9fcdc22e9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate on test data\n",
    "best_model = trained_models[\"XGBoost\"]  # Ensure you are using the correct model\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score :\\n\",accuracy_score(y_test,y_test_pred))\n",
    "print(\"Confusion Maxtrix:\\n\",confusion_matrix(y_test,y_test_pred))\n",
    "print(\"Classification Report:\\n\",classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5b04e-3cca-4118-ab73-5cb52e0cfd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model as a pickle file\n",
    "import pickle\n",
    "\n",
    "# Save the trained model as a pickle file\n",
    "model_data = {\"model\": xgb, \"feature_names\": X.columns.tolist()}\n",
    "with open(\"customer_churn_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_data, f)  # Save model_data instead of just xgb\n",
    "\n",
    "print(\"Model saved to 'customer_churn_model.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd7163-ebb6-4512-9a6a-fbeb7c02c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4b700-0dbb-4061-88b7-b265ba67b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[numerical_features])  # Fit using training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d428b-755c-4b9e-83c5-d053d67dc3ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_importance(best_model)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48620036-9d89-47d0-bb48-e0512a1f33c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Features Before Feature Selection:\", X_train.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e8146-2779-4a85-9f60-40f57d5b2441",
   "metadata": {},
   "source": [
    "###### pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daab273-3ea4-4b17-b042-6f07bb5c367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_tuned = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "    param_distributions=param_grid,\n",
    "    cv=5,\n",
    "    n_iter=10,\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_tuned.fit(X_train_resampled, y_train_resampled)\n",
    "print(\"Best Parameters:\", xgb_tuned.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10f9db1-6de2-42e9-878f-2b7350a19f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter grid based on the best values\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300, 400],  # Test around the best value\n",
    "    'max_depth': [5, 7, 9],  # Check if increasing depth helps\n",
    "    'learning_rate': [0.05, 0.1, 0.15],  # Test slightly lower/higher values\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],  # Feature selection\n",
    "    'subsample': [0.7, 0.8, 0.9]  # Sample selection\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42, \n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=len(y_train[y_train==0]) / len(y_train[y_train==1])  # Handle class imbalance\n",
    ")\n",
    "\n",
    "# Setup GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    verbose=2,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score: {:.4f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Use the best model\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940cb67-2101-4a67-9402-115150e81df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Fit the model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Use SHAP Explainer\n",
    "explainer = shap.Explainer(xgb)\n",
    "shap_values = explainer(X_train_resampled)\n",
    "\n",
    "# Plot SHAP summary\n",
    "shap.summary_plot(shap_values, X_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6dc1fa-ae7c-4949-9c8d-0e6da356873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean absolute SHAP values\n",
    "shap_importance = pd.DataFrame({\n",
    "    'feature': X_train_resampled.columns,\n",
    "    'shap_value': np.abs(shap_values.values).mean(axis=0)\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "shap_importance = shap_importance.sort_values(by=\"shap_value\", ascending=False)\n",
    "\n",
    "# Select top N features (e.g., top 10)\n",
    "top_features = shap_importance.head(14)['feature'].tolist()\n",
    "print(\"Top Features Based on SHAP:\", top_features)\n",
    "\n",
    "# Use only selected features for training\n",
    "X_train_shap = X_train_resampled[top_features]\n",
    "X_test_shap = X_test[top_features]\n",
    "\n",
    "# Train the model with selected features\n",
    "xgb.fit(X_train_shap, y_train_resampled)\n",
    "\n",
    "# Evaluate performance\n",
    "y_pred = xgb.predict(X_test_shap)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy after SHAP Feature Selection:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0473ab-27f0-4115-9935-5beafaf50d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 1️⃣ Train the Baseline Model (Logistic Regression)\n",
    "baseline_model = LogisticRegression(max_iter=500, random_state=42)\n",
    "baseline_model.fit(X_train_resampled, y_train_resampled)  # Use resampled training data\n",
    "\n",
    "# 2️⃣ Make Predictions\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "# 3️⃣ Evaluate Performance\n",
    "print(\"🔹 Baseline Model (Logistic Regression) Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_baseline))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_baseline))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_test, baseline_model.predict_proba(X_test)[:,1]):.4f}\")\n",
    "\n",
    "# 4️⃣ Compare with XGBoost Model\n",
    "y_pred_xgb = best_model.predict(X_test)  # Best XGBoost model you trained\n",
    "\n",
    "print(\"\\n🔹 XGBoost Model Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]):.4f}\")\n",
    "\n",
    "# 5️⃣ Visual Comparison Using ROC Curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_base, tpr_base, _ = roc_curve(y_test, baseline_model.predict_proba(X_test)[:,1])\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, best_model.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.plot(fpr_base, tpr_base, label=\"Logistic Regression (Baseline)\", linestyle=\"--\")\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=\"XGBoost (Optimized)\", linestyle=\"-\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b8fd4-23b0-4c4d-a187-44e60bd86e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define Logistic Regression Model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Perform RFE (Choose how many features you want, e.g., 10)\n",
    "rfe = RFE(estimator=logreg, n_features_to_select=10, step=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get Selected Features\n",
    "selected_features_rfe = X_train.columns[rfe.support_]\n",
    "print(\"Selected Features from RFE:\", selected_features_rfe.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db13cdd-9ce0-496f-b3de-9e8519a49836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize Data (LASSO is sensitive to scale)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Save the scaler\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Scaler successfully saved as 'scaler.pkl'\")\n",
    "\n",
    "# Fit LASSO Model\n",
    "lasso = Lasso(alpha=0.01)  # Adjust alpha to control feature selection\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get Selected Features\n",
    "selected_features_lasso = X_train.columns[lasso.coef_ != 0]\n",
    "print(\"Selected Features from LASSO:\", selected_features_lasso.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d2fcb-b70d-42f7-9001-0b7fb3735506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Filter dataset with selected features (Change to selected_features_lasso if using LASSO)\n",
    "X_train_selected = X_train[selected_features_lasso]\n",
    "X_test_selected = X_test[selected_features_lasso]\n",
    "\n",
    "# Train XGBoost on Selected Features\n",
    "xgb_model = XGBClassifier(n_estimators=300, max_depth=7, learning_rate=0.1, colsample_bytree=0.8, subsample=0.8, random_state=42)\n",
    "xgb_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_model.predict(X_test_selected)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Display Results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(f\"AUC-ROC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e23070c-7372-4b58-ae11-10ee86e90e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  \n",
    "    'max_depth': [3, 5, 7],  \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  \n",
    "    'subsample': [0.8, 1.0],  \n",
    "    'colsample_bytree': [0.8, 1.0]  \n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"\\n🔹 Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the best model\n",
    "best_xgb = XGBClassifier(**best_params, random_state=42, eval_metric='logloss')\n",
    "best_xgb.fit(X_train_selected, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_xgb.predict(X_test_selected)\n",
    "y_pred_proba = best_xgb.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Display Results\n",
    "print(\"\\n🔹 XGBoost Results after Hyperparameter Tuning:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "print(f\"AUC-ROC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e757ee4-cb25-4f74-982e-b40d95825fed",
   "metadata": {},
   "source": [
    "# MODEL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1bd0d5-1e9c-4184-ae7b-69f6673c1865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume these are the names of your numerical features and the columns used during training\n",
    "numerical_features = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "training_columns = X_train.columns  # Or replace with your list of training columns\n",
    "\n",
    "# Create a new data sample with all required features\n",
    "new_data = pd.DataFrame({\n",
    "    'tenure': [12],\n",
    "    'MonthlyCharges': [50],\n",
    "    'TotalCharges': [600],\n",
    "    'gender': [1],            # Example encoded value (e.g., Male=1, Female=0)\n",
    "    'SeniorCitizen': [0],\n",
    "    'Partner': [1],\n",
    "    'Dependents': [0],\n",
    "    'PhoneService': [1],\n",
    "    'MultipleLines': [0],\n",
    "    'InternetService': [2],   # Example encoded value\n",
    "    'OnlineSecurity': [0],\n",
    "    'OnlineBackup': [1],\n",
    "    'DeviceProtection': [0],\n",
    "    'TechSupport': [1],\n",
    "    'StreamingTV': [0],\n",
    "    'StreamingMovies': [1],\n",
    "    'Contract': [1],\n",
    "    'PaperlessBilling': [1],\n",
    "    'PaymentMethod': [2]\n",
    "})\n",
    "\n",
    "# Reindex to ensure the new_data has the same columns as used during training\n",
    "new_data = new_data.reindex(columns=training_columns, fill_value=0)\n",
    "\n",
    "# Apply the scaling transformation to the numerical features\n",
    "new_data[numerical_features] = scaler.transform(new_data[numerical_features])\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"customer_churn_model.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "\n",
    "# Get prediction probabilities using predict_proba\n",
    "probabilities = loaded_model.predict_proba(new_data)\n",
    "\n",
    "# The output probabilities are given per class; for binary classification,\n",
    "# the first column is usually the probability for class 0 (No) and the second for class 1 (Yes)\n",
    "print(\"Prediction Probabilities:\", probabilities)\n",
    "new_prediction = loaded_model.predict(new_data)\n",
    "print(\"🔹 Churn Prediction:\", \"Yes\" if new_prediction[0] == 1 else \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8308d5-6d8a-4228-8383-c38b8a8c9d4c",
   "metadata": {},
   "source": [
    "### MODEL SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff8fb6-5369-4adc-80dc-a7e625b51f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the best model and feature names\n",
    "model_data = {\n",
    "    \"model\": best_xgb, \n",
    "    \"feature_names\": X_train_selected.columns.tolist()\n",
    "}\n",
    "\n",
    "with open(\"customer_churn_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"✅ Best XGBoost Model Saved to 'customer_churn_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64595853-990e-410b-b363-4d5e77c6b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "with open(\"customer_churn_model.pkl\", \"rb\") as file:\n",
    "    loaded_model_data = pickle.load(file)\n",
    "\n",
    "best_model = loaded_model_data[\"model\"]\n",
    "feature_names = loaded_model_data[\"feature_names\"]\n",
    "\n",
    "# Ensure the test data has the same feature order\n",
    "X_test_selected = X_test_selected[feature_names]\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "y_pred_proba = best_model.predict_proba(X_test_selected)[:, 1]\n",
    "\n",
    "# Display results\n",
    "print(\"\\n🔹 Predictions on Test Set:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
